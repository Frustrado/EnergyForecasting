{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, auc, average_precision_score, roc_auc_score,roc_curve\n",
    "\n",
    "import json  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_normalized(y_actual, y_pred):\n",
    "    gini = lambda a, p: 2 * roc_auc_score(a, p) - 1\n",
    "    return gini(y_actual, y_pred) / gini(y_actual, y_actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_error(actual, predicted):\n",
    "    return {'as': [accuracy_score(actual, predicted)],\n",
    "#             'auc':[auc(actual, predicted)],\n",
    "            'apc':[average_precision_score(actual, predicted)],\n",
    "            'f1': [f1_score(actual, predicted)], \n",
    "            'roc_auc': [roc_auc_score(actual, predicted)], \n",
    "            'roc_cur': [roc_curve(actual, predicted)],#moze sie przez to wywalic\n",
    "            'gini': [gini_normalized(actual, predicted)]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configuration():\n",
    "    array_of_configs = []\n",
    "    \n",
    "    svc = {'C':[1.0],\n",
    "           'kernel':['rbf'],\n",
    "           'degree':[3],\n",
    "           'gamma':['scale'],\n",
    "           'coef0':[0.0],\n",
    "           'shrinking':[True],\n",
    "           'probability':[False],\n",
    "           'tol':[0.001],\n",
    "           'cache_size':[200],\n",
    "           'class_weight':[None],\n",
    "           'verbose':[False],\n",
    "           'max_iter':[-1],\n",
    "           'decision_function_shape':['ovr'],\n",
    "           'break_ties':[False],\n",
    "           'random_state':[None]}\n",
    "    \n",
    "    xgbost = {'loss':['deviance'],\n",
    "              'learning_rate':[0.1],\n",
    "              'n_estimators':[100],\n",
    "              'subsample':[1.0],\n",
    "              'criterion':['friedman_mse'],\n",
    "              'min_samples_split':[2],\n",
    "              'min_samples_leaf':[1],\n",
    "              'min_weight_fraction_leaf':[0.0],\n",
    "              'max_depth':[3],\n",
    "              'min_impurity_decrease':[0.0],\n",
    "              'min_impurity_split':[None],\n",
    "              'init':[None],\n",
    "              'random_state':[None],\n",
    "              'max_features':[None],\n",
    "              'verbose':[0],\n",
    "              'max_leaf_nodes':[None],\n",
    "              'warm_start':[False],\n",
    "              'presort':['deprecated'],\n",
    "              'validation_fraction':[0.1],\n",
    "              'n_iter_no_change':[None],\n",
    "              'tol':[0.0001],\n",
    "              'ccp_alpha':[0.0]}\n",
    "    \n",
    "    rf = {'n_estimators':[100],\n",
    "          'criterion':['gini'],\n",
    "          'max_depth':[None],\n",
    "          'min_samples_split':[2],\n",
    "          'min_samples_leaf':[1],\n",
    "          'min_weight_fraction_leaf':[0.0],\n",
    "          'max_features':['auto'],\n",
    "          'max_leaf_nodes':[None],\n",
    "          'min_impurity_decrease':[0.0],\n",
    "          'min_impurity_split':[None],\n",
    "          'bootstrap':[True],\n",
    "          'oob_score':[False],\n",
    "          'n_jobs':[None],\n",
    "          'random_state':[None],\n",
    "          'verbose':[0],\n",
    "          'warm_start':[False],\n",
    "          'class_weight':[None],\n",
    "          'ccp_alpha':[0.0],\n",
    "          'max_samples':[None]}\n",
    "    \n",
    "    sgd = {'loss':['hinge'], \n",
    "           'penalty':['l2'],\n",
    "           'alpha':[0.0001],\n",
    "           'l1_ratio':[0.15],\n",
    "           'fit_intercept':[True],\n",
    "           'max_iter':[1000],\n",
    "           'tol':[0.001],\n",
    "           'shuffle':[True],\n",
    "           'verbose':[0],\n",
    "           'epsilon':[0.1],\n",
    "           'n_jobs':[None],\n",
    "           'random_state':[None],\n",
    "           'learning_rate':['optimal'],\n",
    "           'eta0':[0.0],\n",
    "           'power_t':[0.5],\n",
    "           'early_stopping':[False],\n",
    "           'validation_fraction':[0.1],\n",
    "           'n_iter_no_change':[5],\n",
    "           'class_weight':[None],\n",
    "           'warm_start':[False],\n",
    "           'average':[False]}\n",
    "    \n",
    "    bnb = {'alpha':[1.0],\n",
    "           'binarize':[0.0],\n",
    "           'fit_prior':[True],\n",
    "           'class_prior':[None]}\n",
    "    \n",
    "    mlp = {'hidden_layer_sizes':[(100, )],\n",
    "           'activation':['relu'],\n",
    "           'solver':['adam'],\n",
    "           'alpha':[0.0001],\n",
    "           'batch_size':['auto'],\n",
    "           'learning_rate':['constant'],\n",
    "           'learning_rate_init':[0.001],\n",
    "           'power_t':[0.5],\n",
    "           'max_iter':[200],\n",
    "           'shuffle':[True],\n",
    "           'random_state':[None],\n",
    "           'tol':[0.0001],\n",
    "           'verbose':[False],\n",
    "           'warm_start':[False],\n",
    "           'momentum':[0.9],\n",
    "           'nesterovs_momentum':[True],\n",
    "           'early_stopping':[False],\n",
    "           'validation_fraction':[0.1],\n",
    "           'beta_1':[0.9],\n",
    "           'beta_2':[0.999],\n",
    "           'epsilon':[1e-08],\n",
    "           'n_iter_no_change':[10],\n",
    "           'max_fun':[15000]}\n",
    "    \n",
    "    lsvc = {'penalty':['l2'],\n",
    "            'loss':['squared_hinge'],\n",
    "            'dual':[True],\n",
    "            'tol':[0.0001],\n",
    "            'C':[1.0],\n",
    "            'multi_class':['ovr'],\n",
    "            'fit_intercept':[True],\n",
    "            'intercept_scaling':[1],\n",
    "            'class_weight':[None],\n",
    "            'verbose':[0],\n",
    "            'random_state':[None],\n",
    "            'max_iter':[1000]}\n",
    "    \n",
    "    sc = {}\n",
    "    \n",
    "    array_of_configs.append(svc)\n",
    "    array_of_configs.append(xgbost)\n",
    "    array_of_configs.append(rf)\n",
    "    array_of_configs.append(sgd)\n",
    "    array_of_configs.append(bnb)\n",
    "    array_of_configs.append(mlp)\n",
    "    array_of_configs.append(lsvc)\n",
    "#     array_of_configs.append(sc)\n",
    "    \n",
    "    return array_of_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models():\n",
    "    array_of_models = []\n",
    "    array_of_models.append(SVC())\n",
    "    array_of_models.append(GradientBoostingClassifier())\n",
    "    array_of_models.append(RandomForestClassifier())\n",
    "    array_of_models.append(SGDClassifier())\n",
    "    array_of_models.append(BernoulliNB())\n",
    "    array_of_models.append(MLPClassifier())\n",
    "    array_of_models.append(LinearSVC())\n",
    "#     array_of_models.append(StackingClassifier())\n",
    "    \n",
    "    return array_of_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames=['X', 'Y', 'Z', 'Value'] \n",
    "# series = pd.read_csv('Skin_Non.txt', sep='\\t',names=colnames, header=None, index_col=False)\n",
    "series = pd.read_csv('wine.data',header=None)\n",
    "series['value'] = np.random.randint(0, 2, series.shape[0])\n",
    "data = series.values\n",
    "# X, y = data[:,:-1], data[:, -1]\n",
    "X, y = data[:,:14],data[:,14]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state =0,stratify=y)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_run(config, models):\n",
    "    df = pd.DataFrame()\n",
    "    list_of_models = {}\n",
    "    \n",
    "    for c,m in zip(config,models):\n",
    "        clf = GridSearchCV(m, c)\n",
    "        clf.fit(X_train_std,y_train)\n",
    "#         print(clf.estimator)\n",
    "\n",
    "        if(df.size<1):\n",
    "            df = pd.DataFrame(measure_error(y_test,clf.predict(X_test_std)))\n",
    "            df['model'] = str(m) +\"-\"+ str(1)\n",
    "            list_of_models[str(m) +\"-\"+ str(1)]=clf\n",
    "            df['date']=datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        else:\n",
    "            df1 = pd.DataFrame(measure_error(y_test,clf.predict(X_test_std)))\n",
    "            df1['model'] = str(m) +\"-\"+ str(1)\n",
    "            list_of_models[str(m) +\"-\"+ str(1)]=clf\n",
    "            df1['date']=datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            df= pd.concat([df,df1])\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop('index', inplace=True, axis=1)\n",
    "    return df,list_of_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df,list_of_model_and_configs = initial_run(configuration(),models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_model(dataframe, model, config, list_of_models):\n",
    "    clf = GridSearchCV(model, config)\n",
    "    clf.fit(X_train_std,y_train)\n",
    "#     list_of_models.append(clf)\n",
    "    \n",
    "    df = pd.DataFrame(measure_error(y_test,clf.predict(X_test_std)))\n",
    "    df['model'] = str(clf.estimator) +\"-\"+ str(int(dataframe[dataframe['model'].str.contains(str(clf.estimator))]['model'].tail(1).values[0].split('-')[1])+1)\n",
    "    list_of_models[str(clf.estimator) +\"-\"+ str(int(dataframe[dataframe['model'].str.contains(str(clf.estimator))]['model'].tail(1).values[0].split('-')[1])+1)]=clf\n",
    "    df['date']=datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    dataframe = pd.concat([dataframe,df])\n",
    "    dataframe.reset_index(inplace=True)\n",
    "    dataframe.drop('index', inplace=True, axis=1)\n",
    "    return dataframe, list_of_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, list_of_model_and_configs = add_model(df,SVC(),{'kernel':['linear'],'C':[0.025]},list_of_model_and_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max(df,stat):\n",
    "    return df.loc[df[stat].idxmax()]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## key of best model\n",
    "def get_best_model(models,key):\n",
    "    return list_of_model_and_configs.get(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(estimator=RandomForestClassifier(),\n",
      "             param_grid={'bootstrap': [True], 'ccp_alpha': [0.0],\n",
      "                         'class_weight': [None], 'criterion': ['gini'],\n",
      "                         'max_depth': [None], 'max_features': ['auto'],\n",
      "                         'max_leaf_nodes': [None], 'max_samples': [None],\n",
      "                         'min_impurity_decrease': [0.0],\n",
      "                         'min_impurity_split': [None], 'min_samples_leaf': [1],\n",
      "                         'min_samples_split': [2],\n",
      "                         'min_weight_fraction_leaf': [0.0],\n",
      "                         'n_estimators': [100], 'n_jobs': [None],\n",
      "                         'oob_score': [False], 'random_state': [None],\n",
      "                         'verbose': [0], 'warm_start': [False]})\n"
     ]
    }
   ],
   "source": [
    "print(get_best_model(list_of_model_and_configs,find_max(df,'f1')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_models_toDataframe(models):\n",
    "    list_of_dfs = {}\n",
    "    for k,v in models.items():\n",
    "        key = k.split('-')[0]\n",
    "        if key in list_of_dfs:\n",
    "            if not isinstance(list_of_dfs[key], list):\n",
    "                list_of_dfs[key] = [list_of_dfs[key]]\n",
    "            list_of_dfs[key].append({k:v})\n",
    "        else:\n",
    "            list_of_dfs[key] = ({k:v})\n",
    "    \n",
    "    final_list = []\n",
    "    for k,v in list_of_dfs.items():\n",
    "        df = pd.DataFrame()\n",
    "        if isinstance(v, list): \n",
    "            for i in v:\n",
    "                if(df.size<1):             \n",
    "                    df = pd.DataFrame((i.get(list(i.keys())[0])).param_grid)\n",
    "                    df['model'] = list(i.keys())[0]\n",
    "                else:\n",
    "                    df2 = pd.DataFrame((i.get(list(i.keys())[0])).param_grid)\n",
    "                    df2['model'] = str(list(i.keys())[0])\n",
    "                    df = pd.concat([df,df2])\n",
    "        else:\n",
    "            df = pd.DataFrame((v.get(list(v.keys())[0])).param_grid)\n",
    "            df['model'] = list(v.keys())[0]\n",
    "        final_list.append(df)\n",
    "                         \n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataFrame =convert_models_toDataframe(list_of_model_and_configs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hidden_layer_sizes</th>\n",
       "      <th>activation</th>\n",
       "      <th>solver</th>\n",
       "      <th>alpha</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>learning_rate_init</th>\n",
       "      <th>power_t</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>shuffle</th>\n",
       "      <th>...</th>\n",
       "      <th>momentum</th>\n",
       "      <th>nesterovs_momentum</th>\n",
       "      <th>early_stopping</th>\n",
       "      <th>validation_fraction</th>\n",
       "      <th>beta_1</th>\n",
       "      <th>beta_2</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>n_iter_no_change</th>\n",
       "      <th>max_fun</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(100,)</td>\n",
       "      <td>relu</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>auto</td>\n",
       "      <td>constant</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>200</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>10</td>\n",
       "      <td>15000</td>\n",
       "      <td>MLPClassifier()-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  hidden_layer_sizes activation solver   alpha batch_size learning_rate  \\\n",
       "0             (100,)       relu   adam  0.0001       auto      constant   \n",
       "\n",
       "   learning_rate_init  power_t  max_iter  shuffle  ... momentum  \\\n",
       "0               0.001      0.5       200     True  ...      0.9   \n",
       "\n",
       "   nesterovs_momentum  early_stopping  validation_fraction  beta_1  beta_2  \\\n",
       "0                True           False                  0.1     0.9   0.999   \n",
       "\n",
       "        epsilon  n_iter_no_change  max_fun              model  \n",
       "0  1.000000e-08                10    15000  MLPClassifier()-1  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#przerob na slownik \n",
    "testDataFrame[5].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_configs_to_json(configs):\n",
    "    list_of_json = []\n",
    "    for i in configs:\n",
    "        dict = {}\n",
    "        dict['estimator'] = str((configs.get(i)).estimator)\n",
    "        dict['param_grid'] = (configs.get(i)).param_grid\n",
    "        json_object = json.dumps(dict, indent = 4) \n",
    "        list_of_json.append(json_object)\n",
    "    return list_of_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\\n    \"estimator\": \"SVC()\",\\n    \"param_grid\": {\\n        \"C\": [\\n            1.0\\n        ],\\n        \"kernel\": [\\n            \"rbf\"\\n        ],\\n        \"degree\": [\\n            3\\n        ],\\n        \"gamma\": [\\n            \"scale\"\\n        ],\\n        \"coef0\": [\\n            0.0\\n        ],\\n        \"shrinking\": [\\n            true\\n        ],\\n        \"probability\": [\\n            false\\n        ],\\n        \"tol\": [\\n            0.001\\n        ],\\n        \"cache_size\": [\\n            200\\n        ],\\n        \"class_weight\": [\\n            null\\n        ],\\n        \"verbose\": [\\n            false\\n        ],\\n        \"max_iter\": [\\n            -1\\n        ],\\n        \"decision_function_shape\": [\\n            \"ovr\"\\n        ],\\n        \"break_ties\": [\\n            false\\n        ],\\n        \"random_state\": [\\n            null\\n        ]\\n    }\\n}',\n",
       " '{\\n    \"estimator\": \"GradientBoostingClassifier()\",\\n    \"param_grid\": {\\n        \"loss\": [\\n            \"deviance\"\\n        ],\\n        \"learning_rate\": [\\n            0.1\\n        ],\\n        \"n_estimators\": [\\n            100\\n        ],\\n        \"subsample\": [\\n            1.0\\n        ],\\n        \"criterion\": [\\n            \"friedman_mse\"\\n        ],\\n        \"min_samples_split\": [\\n            2\\n        ],\\n        \"min_samples_leaf\": [\\n            1\\n        ],\\n        \"min_weight_fraction_leaf\": [\\n            0.0\\n        ],\\n        \"max_depth\": [\\n            3\\n        ],\\n        \"min_impurity_decrease\": [\\n            0.0\\n        ],\\n        \"min_impurity_split\": [\\n            null\\n        ],\\n        \"init\": [\\n            null\\n        ],\\n        \"random_state\": [\\n            null\\n        ],\\n        \"max_features\": [\\n            null\\n        ],\\n        \"verbose\": [\\n            0\\n        ],\\n        \"max_leaf_nodes\": [\\n            null\\n        ],\\n        \"warm_start\": [\\n            false\\n        ],\\n        \"presort\": [\\n            \"deprecated\"\\n        ],\\n        \"validation_fraction\": [\\n            0.1\\n        ],\\n        \"n_iter_no_change\": [\\n            null\\n        ],\\n        \"tol\": [\\n            0.0001\\n        ],\\n        \"ccp_alpha\": [\\n            0.0\\n        ]\\n    }\\n}',\n",
       " '{\\n    \"estimator\": \"RandomForestClassifier()\",\\n    \"param_grid\": {\\n        \"n_estimators\": [\\n            100\\n        ],\\n        \"criterion\": [\\n            \"gini\"\\n        ],\\n        \"max_depth\": [\\n            null\\n        ],\\n        \"min_samples_split\": [\\n            2\\n        ],\\n        \"min_samples_leaf\": [\\n            1\\n        ],\\n        \"min_weight_fraction_leaf\": [\\n            0.0\\n        ],\\n        \"max_features\": [\\n            \"auto\"\\n        ],\\n        \"max_leaf_nodes\": [\\n            null\\n        ],\\n        \"min_impurity_decrease\": [\\n            0.0\\n        ],\\n        \"min_impurity_split\": [\\n            null\\n        ],\\n        \"bootstrap\": [\\n            true\\n        ],\\n        \"oob_score\": [\\n            false\\n        ],\\n        \"n_jobs\": [\\n            null\\n        ],\\n        \"random_state\": [\\n            null\\n        ],\\n        \"verbose\": [\\n            0\\n        ],\\n        \"warm_start\": [\\n            false\\n        ],\\n        \"class_weight\": [\\n            null\\n        ],\\n        \"ccp_alpha\": [\\n            0.0\\n        ],\\n        \"max_samples\": [\\n            null\\n        ]\\n    }\\n}',\n",
       " '{\\n    \"estimator\": \"SGDClassifier()\",\\n    \"param_grid\": {\\n        \"loss\": [\\n            \"hinge\"\\n        ],\\n        \"penalty\": [\\n            \"l2\"\\n        ],\\n        \"alpha\": [\\n            0.0001\\n        ],\\n        \"l1_ratio\": [\\n            0.15\\n        ],\\n        \"fit_intercept\": [\\n            true\\n        ],\\n        \"max_iter\": [\\n            1000\\n        ],\\n        \"tol\": [\\n            0.001\\n        ],\\n        \"shuffle\": [\\n            true\\n        ],\\n        \"verbose\": [\\n            0\\n        ],\\n        \"epsilon\": [\\n            0.1\\n        ],\\n        \"n_jobs\": [\\n            null\\n        ],\\n        \"random_state\": [\\n            null\\n        ],\\n        \"learning_rate\": [\\n            \"optimal\"\\n        ],\\n        \"eta0\": [\\n            0.0\\n        ],\\n        \"power_t\": [\\n            0.5\\n        ],\\n        \"early_stopping\": [\\n            false\\n        ],\\n        \"validation_fraction\": [\\n            0.1\\n        ],\\n        \"n_iter_no_change\": [\\n            5\\n        ],\\n        \"class_weight\": [\\n            null\\n        ],\\n        \"warm_start\": [\\n            false\\n        ],\\n        \"average\": [\\n            false\\n        ]\\n    }\\n}',\n",
       " '{\\n    \"estimator\": \"BernoulliNB()\",\\n    \"param_grid\": {\\n        \"alpha\": [\\n            1.0\\n        ],\\n        \"binarize\": [\\n            0.0\\n        ],\\n        \"fit_prior\": [\\n            true\\n        ],\\n        \"class_prior\": [\\n            null\\n        ]\\n    }\\n}',\n",
       " '{\\n    \"estimator\": \"MLPClassifier()\",\\n    \"param_grid\": {\\n        \"hidden_layer_sizes\": [\\n            [\\n                100\\n            ]\\n        ],\\n        \"activation\": [\\n            \"relu\"\\n        ],\\n        \"solver\": [\\n            \"adam\"\\n        ],\\n        \"alpha\": [\\n            0.0001\\n        ],\\n        \"batch_size\": [\\n            \"auto\"\\n        ],\\n        \"learning_rate\": [\\n            \"constant\"\\n        ],\\n        \"learning_rate_init\": [\\n            0.001\\n        ],\\n        \"power_t\": [\\n            0.5\\n        ],\\n        \"max_iter\": [\\n            200\\n        ],\\n        \"shuffle\": [\\n            true\\n        ],\\n        \"random_state\": [\\n            null\\n        ],\\n        \"tol\": [\\n            0.0001\\n        ],\\n        \"verbose\": [\\n            false\\n        ],\\n        \"warm_start\": [\\n            false\\n        ],\\n        \"momentum\": [\\n            0.9\\n        ],\\n        \"nesterovs_momentum\": [\\n            true\\n        ],\\n        \"early_stopping\": [\\n            false\\n        ],\\n        \"validation_fraction\": [\\n            0.1\\n        ],\\n        \"beta_1\": [\\n            0.9\\n        ],\\n        \"beta_2\": [\\n            0.999\\n        ],\\n        \"epsilon\": [\\n            1e-08\\n        ],\\n        \"n_iter_no_change\": [\\n            10\\n        ],\\n        \"max_fun\": [\\n            15000\\n        ]\\n    }\\n}',\n",
       " '{\\n    \"estimator\": \"LinearSVC()\",\\n    \"param_grid\": {\\n        \"penalty\": [\\n            \"l2\"\\n        ],\\n        \"loss\": [\\n            \"squared_hinge\"\\n        ],\\n        \"dual\": [\\n            true\\n        ],\\n        \"tol\": [\\n            0.0001\\n        ],\\n        \"C\": [\\n            1.0\\n        ],\\n        \"multi_class\": [\\n            \"ovr\"\\n        ],\\n        \"fit_intercept\": [\\n            true\\n        ],\\n        \"intercept_scaling\": [\\n            1\\n        ],\\n        \"class_weight\": [\\n            null\\n        ],\\n        \"verbose\": [\\n            0\\n        ],\\n        \"random_state\": [\\n            null\\n        ],\\n        \"max_iter\": [\\n            1000\\n        ]\\n    }\\n}',\n",
       " '{\\n    \"estimator\": \"SVC()\",\\n    \"param_grid\": {\\n        \"kernel\": [\\n            \"linear\"\\n        ],\\n        \"C\": [\\n            0.025\\n        ]\\n    }\\n}']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_configs_to_json(list_of_model_and_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- measure metrics\n",
    "- json\n",
    "- modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.utils import all_estimators\n",
    "classifiers=[est for est in all_estimators() if issubclass(est[1], ClassifierMixin)]\n",
    "print(classifiers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_model_and_configs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
